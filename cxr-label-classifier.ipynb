{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6953534,"sourceType":"datasetVersion","datasetId":3993839},{"sourceId":6976394,"sourceType":"datasetVersion","datasetId":4008839},{"sourceId":6976823,"sourceType":"datasetVersion","datasetId":4009115}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Import Libraries","metadata":{}},{"cell_type":"code","source":"!pip install transformers\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport torch\nfrom torch.nn import BCEWithLogitsLoss, BCELoss\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\nimport pickle\nfrom transformers import *\nfrom tqdm import tqdm, trange\nfrom ast import literal_eval","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-21T03:57:23.645143Z","iopub.execute_input":"2023-11-21T03:57:23.645409Z","iopub.status.idle":"2023-11-21T04:00:52.532493Z","shell.execute_reply.started":"2023-11-21T03:57:23.645382Z","shell.execute_reply":"2023-11-21T04:00:52.531635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device_name = tf.test.gpu_device_name()\nif device_name != '/device:GPU:0':\n  raise SystemError('GPU device not found')\nprint('Found GPU at: {}'.format(device_name))","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:00:52.534263Z","iopub.execute_input":"2023-11-21T04:00:52.534919Z","iopub.status.idle":"2023-11-21T04:00:52.547601Z","shell.execute_reply.started":"2023-11-21T04:00:52.534890Z","shell.execute_reply":"2023-11-21T04:00:52.546624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_gpu = torch.cuda.device_count()\ntorch.cuda.get_device_name(0)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:00:52.548610Z","iopub.execute_input":"2023-11-21T04:00:52.548846Z","iopub.status.idle":"2023-11-21T04:00:52.562490Z","shell.execute_reply.started":"2023-11-21T04:00:52.548825Z","shell.execute_reply":"2023-11-21T04:00:52.561666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load & Preprocess Training Data","metadata":{}},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) ","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:00:52.564947Z","iopub.execute_input":"2023-11-21T04:00:52.565293Z","iopub.status.idle":"2023-11-21T04:00:53.671645Z","shell.execute_reply.started":"2023-11-21T04:00:52.565262Z","shell.execute_reply":"2023-11-21T04:00:53.670630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/labeledreports/labeled_reports.csv') #jigsaw-toxic-comment-classification-challenge\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:00:53.673031Z","iopub.execute_input":"2023-11-21T04:00:53.674047Z","iopub.status.idle":"2023-11-21T04:00:54.577509Z","shell.execute_reply.started":"2023-11-21T04:00:53.674007Z","shell.execute_reply":"2023-11-21T04:00:54.576458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.fillna(0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:00:54.578947Z","iopub.execute_input":"2023-11-21T04:00:54.579399Z","iopub.status.idle":"2023-11-21T04:00:54.611703Z","shell.execute_reply.started":"2023-11-21T04:00:54.579359Z","shell.execute_reply":"2023-11-21T04:00:54.610973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.replace(to_replace=-1, \n           value=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:00:54.612785Z","iopub.execute_input":"2023-11-21T04:00:54.613061Z","iopub.status.idle":"2023-11-21T04:00:54.637974Z","shell.execute_reply.started":"2023-11-21T04:00:54.613037Z","shell.execute_reply":"2023-11-21T04:00:54.636879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:00:54.640933Z","iopub.execute_input":"2023-11-21T04:00:54.641643Z","iopub.status.idle":"2023-11-21T04:00:54.649077Z","shell.execute_reply.started":"2023-11-21T04:00:54.641616Z","shell.execute_reply":"2023-11-21T04:00:54.648198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Unique comments: ', df['Report Impression'].nunique() == df.shape[0])\nprint('Null values: ', df.isnull().values.any())","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:00:54.650167Z","iopub.execute_input":"2023-11-21T04:00:54.650490Z","iopub.status.idle":"2023-11-21T04:00:54.772329Z","shell.execute_reply.started":"2023-11-21T04:00:54.650464Z","shell.execute_reply":"2023-11-21T04:00:54.771399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('average sentence length: ', df['Report Impression'].str.split().str.len().mean())\nprint('stdev sentence length: ', df['Report Impression'].str.split().str.len().std())","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:00:54.776787Z","iopub.execute_input":"2023-11-21T04:00:54.777081Z","iopub.status.idle":"2023-11-21T04:00:56.737376Z","shell.execute_reply.started":"2023-11-21T04:00:54.777054Z","shell.execute_reply":"2023-11-21T04:00:56.736368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = df.columns\nlabel_cols = list(cols[1:])\nnum_labels = len(label_cols)\nprint('Label columns: ', label_cols)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:00:56.738532Z","iopub.execute_input":"2023-11-21T04:00:56.738857Z","iopub.status.idle":"2023-11-21T04:00:56.744548Z","shell.execute_reply.started":"2023-11-21T04:00:56.738831Z","shell.execute_reply":"2023-11-21T04:00:56.743566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Count of 1 per label: \\n', df[label_cols].sum(), '\\n') # Label counts, may need to downsample or upsample\nprint('Count of 0 per label: \\n', df[label_cols].eq(0).sum())","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:00:56.745750Z","iopub.execute_input":"2023-11-21T04:00:56.746030Z","iopub.status.idle":"2023-11-21T04:00:56.900398Z","shell.execute_reply.started":"2023-11-21T04:00:56.746006Z","shell.execute_reply":"2023-11-21T04:00:56.899483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:00:56.901410Z","iopub.execute_input":"2023-11-21T04:00:56.901689Z","iopub.status.idle":"2023-11-21T04:00:56.907752Z","shell.execute_reply.started":"2023-11-21T04:00:56.901666Z","shell.execute_reply":"2023-11-21T04:00:56.906850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ID=list(range(0,len(df)))","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:00:56.908995Z","iopub.execute_input":"2023-11-21T04:00:56.909526Z","iopub.status.idle":"2023-11-21T04:00:56.919896Z","shell.execute_reply.started":"2023-11-21T04:00:56.909495Z","shell.execute_reply":"2023-11-21T04:00:56.919028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.insert(0,\"id\",ID)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:00:56.921116Z","iopub.execute_input":"2023-11-21T04:00:56.921469Z","iopub.status.idle":"2023-11-21T04:00:56.973161Z","shell.execute_reply.started":"2023-11-21T04:00:56.921439Z","shell.execute_reply":"2023-11-21T04:00:56.972340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.sample(frac=1).reset_index(drop=True) #shuffle rows","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:00:56.974297Z","iopub.execute_input":"2023-11-21T04:00:56.974595Z","iopub.status.idle":"2023-11-21T04:00:57.010935Z","shell.execute_reply.started":"2023-11-21T04:00:56.974571Z","shell.execute_reply":"2023-11-21T04:00:57.010175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['one_hot_labels'] = list(df[label_cols].values)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:00:57.012118Z","iopub.execute_input":"2023-11-21T04:00:57.012688Z","iopub.status.idle":"2023-11-21T04:00:57.071220Z","shell.execute_reply.started":"2023-11-21T04:00:57.012652Z","shell.execute_reply":"2023-11-21T04:00:57.070251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = list(df.one_hot_labels.values)\ncomments = list(df['Report Impression'].values)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:00:57.072151Z","iopub.execute_input":"2023-11-21T04:00:57.072425Z","iopub.status.idle":"2023-11-21T04:00:57.086949Z","shell.execute_reply.started":"2023-11-21T04:00:57.072392Z","shell.execute_reply":"2023-11-21T04:00:57.086077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length = 100\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) # tokenizer\nencodings = tokenizer.batch_encode_plus(comments,max_length=max_length,pad_to_max_length=True) # tokenizer's encoding method\nprint('tokenizer outputs: ', encodings.keys())","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:00:57.088070Z","iopub.execute_input":"2023-11-21T04:00:57.088387Z","iopub.status.idle":"2023-11-21T04:04:43.623736Z","shell.execute_reply.started":"2023-11-21T04:00:57.088362Z","shell.execute_reply":"2023-11-21T04:04:43.622739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids = encodings['input_ids'] # tokenized and encoded sentences\ntoken_type_ids = encodings['token_type_ids'] # token type ids\nattention_masks = encodings['attention_mask'] # attention masks","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:04:43.627460Z","iopub.execute_input":"2023-11-21T04:04:43.627762Z","iopub.status.idle":"2023-11-21T04:04:43.632517Z","shell.execute_reply.started":"2023-11-21T04:04:43.627734Z","shell.execute_reply":"2023-11-21T04:04:43.631527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identifying indices of 'one_hot_labels' entries that only occur once - this will allow us to stratify split our training data later\nlabel_counts = df.one_hot_labels.astype(str).value_counts()\none_freq = label_counts[label_counts==1].keys()\none_freq_idxs = sorted(list(df[df.one_hot_labels.astype(str).isin(one_freq)].index), reverse=True)\nprint('df label indices with only one instance: ', one_freq_idxs)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:04:43.633793Z","iopub.execute_input":"2023-11-21T04:04:43.634085Z","iopub.status.idle":"2023-11-21T04:05:14.900570Z","shell.execute_reply.started":"2023-11-21T04:04:43.634059Z","shell.execute_reply":"2023-11-21T04:05:14.899393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Gathering single instance inputs to force into the training set after stratified split\none_freq_input_ids = [input_ids.pop(i) for i in one_freq_idxs]\none_freq_token_types = [token_type_ids.pop(i) for i in one_freq_idxs]\none_freq_attention_masks = [attention_masks.pop(i) for i in one_freq_idxs]\none_freq_labels = [labels.pop(i) for i in one_freq_idxs]","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:05:14.901848Z","iopub.execute_input":"2023-11-21T04:05:14.902214Z","iopub.status.idle":"2023-11-21T04:05:14.926974Z","shell.execute_reply.started":"2023-11-21T04:05:14.902175Z","shell.execute_reply":"2023-11-21T04:05:14.926197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use train_test_split to split our data into train and validation sets\n\ntrain_inputs, validation_inputs, train_labels, validation_labels, train_token_types, validation_token_types, train_masks, validation_masks = train_test_split(input_ids, labels, token_type_ids,attention_masks,\n                                                            random_state=2020, test_size=0.10, stratify = labels)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:05:14.928087Z","iopub.execute_input":"2023-11-21T04:05:14.928392Z","iopub.status.idle":"2023-11-21T04:05:16.871990Z","shell.execute_reply.started":"2023-11-21T04:05:14.928368Z","shell.execute_reply":"2023-11-21T04:05:16.871180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_labels[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:05:16.873138Z","iopub.execute_input":"2023-11-21T04:05:16.873465Z","iopub.status.idle":"2023-11-21T04:05:16.879517Z","shell.execute_reply.started":"2023-11-21T04:05:16.873437Z","shell.execute_reply":"2023-11-21T04:05:16.878593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add one frequency data to train data\ntrain_inputs.extend(one_freq_input_ids)\ntrain_labels.extend(one_freq_labels)\ntrain_masks.extend(one_freq_attention_masks)\ntrain_token_types.extend(one_freq_token_types)\n\n# Convert all of our data into torch tensors, the required datatype for our model\ntrain_inputs = torch.tensor(train_inputs)\ntrain_labels = torch.tensor(train_labels)\ntrain_masks = torch.tensor(train_masks)\ntrain_token_types = torch.tensor(train_token_types)\n\nvalidation_inputs = torch.tensor(validation_inputs)\nvalidation_labels = torch.tensor(validation_labels)\nvalidation_masks = torch.tensor(validation_masks)\nvalidation_token_types = torch.tensor(validation_token_types)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:05:16.880788Z","iopub.execute_input":"2023-11-21T04:05:16.881071Z","iopub.status.idle":"2023-11-21T04:05:26.820566Z","shell.execute_reply.started":"2023-11-21T04:05:16.881047Z","shell.execute_reply":"2023-11-21T04:05:26.819734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select a batch size for training. For fine-tuning with XLNet, the authors recommend a batch size of 32, 48, or 128. We will use 32 here to avoid memory issues.\nbatch_size = 32\n\n# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n# with an iterator the entire dataset does not need to be loaded into memory\n\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels, train_token_types)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\nvalidation_data = TensorDataset(validation_inputs, validation_masks, validation_labels, validation_token_types)\nvalidation_sampler = SequentialSampler(validation_data)\nvalidation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:05:26.821674Z","iopub.execute_input":"2023-11-21T04:05:26.821965Z","iopub.status.idle":"2023-11-21T04:05:26.828397Z","shell.execute_reply.started":"2023-11-21T04:05:26.821940Z","shell.execute_reply":"2023-11-21T04:05:26.827439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(validation_dataloader,'validation_data_loader')\ntorch.save(train_dataloader,'train_data_loader')","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:05:26.829592Z","iopub.execute_input":"2023-11-21T04:05:26.829966Z","iopub.status.idle":"2023-11-21T04:05:27.098238Z","shell.execute_reply.started":"2023-11-21T04:05:26.829928Z","shell.execute_reply":"2023-11-21T04:05:27.097364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load Model & Set Params\n","metadata":{}},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:05:27.103846Z","iopub.execute_input":"2023-11-21T04:05:27.104432Z","iopub.status.idle":"2023-11-21T04:05:30.934503Z","shell.execute_reply.started":"2023-11-21T04:05:27.104403Z","shell.execute_reply":"2023-11-21T04:05:30.933453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load model, the pretrained model will include a single linear classification layer on top for classification. \n\nmodel.cuda()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:05:30.935977Z","iopub.execute_input":"2023-11-21T04:05:30.936386Z","iopub.status.idle":"2023-11-21T04:05:31.111278Z","shell.execute_reply.started":"2023-11-21T04:05:30.936353Z","shell.execute_reply":"2023-11-21T04:05:31.110168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# setting custom optimization parameters. You may implement a scheduler here as well.\nparam_optimizer = list(model.named_parameters())\nno_decay = ['bias', 'gamma', 'beta']\noptimizer_grouped_parameters = [\n    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n     'weight_decay_rate': 0.01},\n    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n     'weight_decay_rate': 0.0}\n]","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:05:31.112924Z","iopub.execute_input":"2023-11-21T04:05:31.113364Z","iopub.status.idle":"2023-11-21T04:05:31.122128Z","shell.execute_reply.started":"2023-11-21T04:05:31.113316Z","shell.execute_reply":"2023-11-21T04:05:31.121026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(optimizer_grouped_parameters,lr=2e-5,correct_bias=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:05:31.123376Z","iopub.execute_input":"2023-11-21T04:05:31.123666Z","iopub.status.idle":"2023-11-21T04:05:31.145883Z","shell.execute_reply.started":"2023-11-21T04:05:31.123632Z","shell.execute_reply":"2023-11-21T04:05:31.144784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train Model\nThe HuggingFace library is configured for multiclass classification out of the box using “Categorical Cross Entropy” as the loss function.","metadata":{}},{"cell_type":"code","source":"# Store our loss and accuracy for plotting\ntrain_loss_set = []\n\n# Number of training epochs (authors recommend between 2 and 4)\nepochs = 3\n\n# trange is a tqdm wrapper around the normal python range\nfor _ in trange(epochs, desc=\"Epoch\"):\n\n  # Training\n  \n  # Set our model to training mode (as opposed to evaluation mode)\n  model.train()\n\n  # Tracking variables\n  tr_loss = 0 #running loss\n  nb_tr_examples, nb_tr_steps = 0, 0\n  \n  # Train the data for one epoch\n  for step, batch in enumerate(train_dataloader):\n    # Add batch to GPU\n    batch = tuple(t.to(device) for t in batch)\n    # Unpack the inputs from our dataloader\n    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n    # Clear out the gradients (by default they accumulate)\n    optimizer.zero_grad()\n\n    # # Forward pass for multiclass classification\n    # outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n    # loss = outputs[0]\n    # logits = outputs[1]\n\n    # Forward pass for multilabel classification\n    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n    logits = outputs[0]\n    loss_func = BCEWithLogitsLoss() \n    loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n    # loss_func = BCELoss() \n    # loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n    train_loss_set.append(loss.item())    \n\n    # Backward pass\n    loss.backward()\n    # Update parameters and take a step using the computed gradient\n    optimizer.step()\n    # scheduler.step()\n    # Update tracking variables\n    tr_loss += loss.item()\n    nb_tr_examples += b_input_ids.size(0)\n    nb_tr_steps += 1\n\n  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n\n###############################################################################\n\n  # Validation\n\n  # Put model in evaluation mode to evaluate loss on the validation set\n  model.eval()\n\n  # Variables to gather full output\n  logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n\n  # Predict\n  for i, batch in enumerate(validation_dataloader):\n    batch = tuple(t.to(device) for t in batch)\n    # Unpack the inputs from our dataloader\n    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n    with torch.no_grad():\n      # Forward pass\n      outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n      b_logit_pred = outs[0]\n      pred_label = torch.sigmoid(b_logit_pred)\n\n      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n      pred_label = pred_label.to('cpu').numpy()\n      b_labels = b_labels.to('cpu').numpy()\n\n    tokenized_texts.append(b_input_ids)\n    logit_preds.append(b_logit_pred)\n    true_labels.append(b_labels)\n    pred_labels.append(pred_label)\n\n  # Flatten outputs\n  pred_labels = [item for sublist in pred_labels for item in sublist]\n  true_labels = [item for sublist in true_labels for item in sublist]\n\n  # Calculate Accuracy\n  threshold = 0.50\n  pred_bools = [pl>threshold for pl in pred_labels]\n  true_bools = [tl==1 for tl in true_labels]\n  val_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')*100\n  val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n\n  print('F1 Validation Accuracy: ', val_f1_accuracy)\n  print('Flat Validation Accuracy: ', val_flat_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T18:05:06.573844Z","iopub.execute_input":"2023-11-15T18:05:06.574282Z","iopub.status.idle":"2023-11-15T19:21:17.831835Z","shell.execute_reply.started":"2023-11-15T18:05:06.574244Z","shell.execute_reply":"2023-11-15T19:21:17.830835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction & Metrics\nPrediction for our test set is similar to our validation set. Here we will be loading, preprocessing, and predicting with the test data.","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/input/cxr-text-classifier/text_classifier_model.pt'))","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:05:31.147168Z","iopub.execute_input":"2023-11-21T04:05:31.147527Z","iopub.status.idle":"2023-11-21T04:05:35.471005Z","shell.execute_reply.started":"2023-11-21T04:05:31.147490Z","shell.execute_reply":"2023-11-21T04:05:35.470006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/reptest/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:05:35.472202Z","iopub.execute_input":"2023-11-21T04:05:35.472525Z","iopub.status.idle":"2023-11-21T04:05:35.508584Z","shell.execute_reply.started":"2023-11-21T04:05:35.472498Z","shell.execute_reply":"2023-11-21T04:05:35.507644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ID=list(range(0,len(test_df)))\ntest_df.insert(0,\"id\",ID)\ntest_df.fillna(0, inplace=True)\ntest_df.replace(to_replace=-1, \n           value=1,inplace=True)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:05:35.509780Z","iopub.execute_input":"2023-11-21T04:05:35.510106Z","iopub.status.idle":"2023-11-21T04:05:35.545966Z","shell.execute_reply.started":"2023-11-21T04:05:35.510077Z","shell.execute_reply":"2023-11-21T04:05:35.545034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_label_cols = list(test_df.columns[2:])\nprint('Null values: ', test_df.isnull().values.any()) #should not be any null sentences or labels\nprint('Same columns between train and test: ', label_cols == test_label_cols) #columns should be the same\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:06:39.015951Z","iopub.execute_input":"2023-11-21T04:06:39.016791Z","iopub.status.idle":"2023-11-21T04:06:39.048270Z","shell.execute_reply.started":"2023-11-21T04:06:39.016748Z","shell.execute_reply":"2023-11-21T04:06:39.046973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = test_df[~test_df[test_label_cols].eq(-1).any(axis=1)] #remove irrelevant rows/comments with -1 values\ntest_df['one_hot_labels'] = list(test_df[test_label_cols].values)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:06:44.210030Z","iopub.execute_input":"2023-11-21T04:06:44.210417Z","iopub.status.idle":"2023-11-21T04:06:44.244045Z","shell.execute_reply.started":"2023-11-21T04:06:44.210385Z","shell.execute_reply":"2023-11-21T04:06:44.243170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.columns","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:06:48.569831Z","iopub.execute_input":"2023-11-21T04:06:48.570717Z","iopub.status.idle":"2023-11-21T04:06:48.576873Z","shell.execute_reply.started":"2023-11-21T04:06:48.570679Z","shell.execute_reply":"2023-11-21T04:06:48.575909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Gathering input data\ntest_labels = list(test_df.one_hot_labels.values)\ntest_comments = list(test_df['Report Impression'].values)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:06:50.889961Z","iopub.execute_input":"2023-11-21T04:06:50.890723Z","iopub.status.idle":"2023-11-21T04:06:50.896056Z","shell.execute_reply.started":"2023-11-21T04:06:50.890686Z","shell.execute_reply":"2023-11-21T04:06:50.895055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encoding input data\ntest_encodings = tokenizer.batch_encode_plus(test_comments,max_length=max_length,pad_to_max_length=True)\ntest_input_ids = test_encodings['input_ids']\ntest_token_type_ids = test_encodings['token_type_ids']\ntest_attention_masks = test_encodings['attention_mask']","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:06:53.370351Z","iopub.execute_input":"2023-11-21T04:06:53.371040Z","iopub.status.idle":"2023-11-21T04:06:58.445777Z","shell.execute_reply.started":"2023-11-21T04:06:53.371007Z","shell.execute_reply":"2023-11-21T04:06:58.444959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make tensors out of data\ntest_inputs = torch.tensor(test_input_ids)\ntest_labels = torch.tensor(test_labels)\ntest_masks = torch.tensor(test_attention_masks)\ntest_token_types = torch.tensor(test_token_type_ids)\n# Create test dataloader\ntest_data = TensorDataset(test_inputs, test_masks, test_labels, test_token_types)\ntest_sampler = SequentialSampler(test_data)\ntest_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:06:58.447628Z","iopub.execute_input":"2023-11-21T04:06:58.448279Z","iopub.status.idle":"2023-11-21T04:06:58.699881Z","shell.execute_reply.started":"2023-11-21T04:06:58.448241Z","shell.execute_reply":"2023-11-21T04:06:58.698467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test\n\n# Put model in evaluation mode to evaluate loss on the validation set\nmodel.eval()\n\n#track variables\nlogit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n\n# Predict\nfor i, batch in enumerate(test_dataloader):\n  batch = tuple(t.to(device) for t in batch)\n  # Unpack the inputs from our dataloader\n  b_input_ids, b_input_mask, b_labels, b_token_types = batch\n  with torch.no_grad():\n    # Forward pass\n    outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n    b_logit_pred = outs[0]\n    pred_label = torch.sigmoid(b_logit_pred)\n\n    b_logit_pred = b_logit_pred.detach().cpu().numpy()\n    pred_label = pred_label.to('cpu').numpy()\n    b_labels = b_labels.to('cpu').numpy()\n\n  tokenized_texts.append(b_input_ids)\n  logit_preds.append(b_logit_pred)\n  true_labels.append(b_labels)\n  pred_labels.append(pred_label)\n\n# Flatten outputs\ntokenized_texts = [item for sublist in tokenized_texts for item in sublist]\npred_labels = [item for sublist in pred_labels for item in sublist]\ntrue_labels = [item for sublist in true_labels for item in sublist]\n# Converting flattened binary values to boolean values\ntrue_bools = [tl==1 for tl in true_labels]","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:06:58.701034Z","iopub.execute_input":"2023-11-21T04:06:58.701428Z","iopub.status.idle":"2023-11-21T04:07:17.217423Z","shell.execute_reply.started":"2023-11-21T04:06:58.701392Z","shell.execute_reply":"2023-11-21T04:07:17.216318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_bools = [pl>0.50 for pl in pred_labels] #boolean output after thresholding\n\n# Print and save classification report\nprint('Test F1 Accuracy: ', f1_score(true_bools, pred_bools,average='micro'))\nprint('Test Flat Accuracy: ', accuracy_score(true_bools, pred_bools),'\\n')\nclf_report = classification_report(true_bools,pred_bools,target_names=test_label_cols)\npickle.dump(clf_report, open('classification_report.txt','wb')) #save report\nprint(clf_report)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:07:24.225384Z","iopub.execute_input":"2023-11-21T04:07:24.226247Z","iopub.status.idle":"2023-11-21T04:07:24.293506Z","shell.execute_reply.started":"2023-11-21T04:07:24.226214Z","shell.execute_reply":"2023-11-21T04:07:24.292628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Output DataFrame\nCreating a dataframe of outputs that show sentences and their classification.","metadata":{}},{"cell_type":"code","source":"idx2label = dict(zip(range(14),label_cols))\nprint(idx2label)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:07:52.121494Z","iopub.execute_input":"2023-11-21T04:07:52.121917Z","iopub.status.idle":"2023-11-21T04:07:52.127724Z","shell.execute_reply.started":"2023-11-21T04:07:52.121884Z","shell.execute_reply":"2023-11-21T04:07:52.126460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting indices of where boolean one hot vector true_bools is True so we can use idx2label to gather label names\ntrue_label_idxs, pred_label_idxs=[],[]\nfor vals in true_bools:\n  true_label_idxs.append(np.where(vals)[0].flatten().tolist())\nfor vals in pred_bools:\n  pred_label_idxs.append(np.where(vals)[0].flatten().tolist())","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:07:52.740844Z","iopub.execute_input":"2023-11-21T04:07:52.741498Z","iopub.status.idle":"2023-11-21T04:07:52.765001Z","shell.execute_reply.started":"2023-11-21T04:07:52.741461Z","shell.execute_reply":"2023-11-21T04:07:52.764087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Gathering vectors of label names using idx2label\ntrue_label_texts, pred_label_texts = [], []\nfor vals in true_label_idxs:\n  if vals:\n    true_label_texts.append([idx2label[val] for val in vals])\n  else:\n    true_label_texts.append(vals)\n\nfor vals in pred_label_idxs:\n  if vals:\n    pred_label_texts.append([idx2label[val] for val in vals])\n  else:\n    pred_label_texts.append(vals)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:07:56.540975Z","iopub.execute_input":"2023-11-21T04:07:56.541352Z","iopub.status.idle":"2023-11-21T04:07:56.550371Z","shell.execute_reply.started":"2023-11-21T04:07:56.541319Z","shell.execute_reply":"2023-11-21T04:07:56.549466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Decoding input ids to comment text\ncomment_texts = [tokenizer.decode(text,skip_special_tokens=True,clean_up_tokenization_spaces=False) for text in tokenized_texts]","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:08:00.772156Z","iopub.execute_input":"2023-11-21T04:08:00.772531Z","iopub.status.idle":"2023-11-21T04:08:07.316706Z","shell.execute_reply.started":"2023-11-21T04:08:00.772503Z","shell.execute_reply":"2023-11-21T04:08:07.315821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting lists to df\ncomparisons_df = pd.DataFrame({'comment_text': comment_texts, 'true_labels': true_label_texts, 'pred_labels':pred_label_texts})\ncomparisons_df.to_csv('comparisons.csv')\ncomparisons_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:08:07.318342Z","iopub.execute_input":"2023-11-21T04:08:07.318638Z","iopub.status.idle":"2023-11-21T04:08:07.380086Z","shell.execute_reply.started":"2023-11-21T04:08:07.318611Z","shell.execute_reply":"2023-11-21T04:08:07.379069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Optimizing threshold value for micro F1 score\nDoing this may result in a trade offs between precision, flat accuracy and micro F1 accuracy. You may tune the threshold however you want.","metadata":{}},{"cell_type":"code","source":"# Calculate Accuracy - maximize F1 accuracy by tuning threshold values. First with 'macro_thresholds' on the order of e^-1 then with 'micro_thresholds' on the order of e^-2\n\nmacro_thresholds = np.array(range(1,10))/10\n\nf1_results, flat_acc_results = [], []\nfor th in macro_thresholds:\n  pred_bools = [pl>th for pl in pred_labels]\n  test_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')\n  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n  f1_results.append(test_f1_accuracy)\n  flat_acc_results.append(test_flat_accuracy)\n\nbest_macro_th = macro_thresholds[np.argmax(f1_results)] #best macro threshold value\n\nmicro_thresholds = (np.array(range(10))/100)+best_macro_th #calculating micro threshold values\n\nf1_results, flat_acc_results = [], []\nfor th in micro_thresholds:\n  pred_bools = [pl>th for pl in pred_labels]\n  test_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')\n  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n  f1_results.append(test_f1_accuracy)\n  flat_acc_results.append(test_flat_accuracy)\n\nbest_f1_idx = np.argmax(f1_results) #best threshold value\n\n# Printing and saving classification report\nprint('Best Threshold: ', micro_thresholds[best_f1_idx])\nprint('Test F1 Accuracy: ', f1_results[best_f1_idx])\nprint('Test Flat Accuracy: ', flat_acc_results[best_f1_idx], '\\n')\n\nbest_pred_bools = [pl>micro_thresholds[best_f1_idx] for pl in pred_labels]\nclf_report_optimized = classification_report(true_bools,best_pred_bools, target_names=label_cols)\npickle.dump(clf_report_optimized, open('classification_report_optimized.txt','wb'))\nprint(clf_report_optimized)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T04:08:07.381247Z","iopub.execute_input":"2023-11-21T04:08:07.381542Z","iopub.status.idle":"2023-11-21T04:08:07.990486Z","shell.execute_reply.started":"2023-11-21T04:08:07.381516Z","shell.execute_reply":"2023-11-21T04:08:07.989295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### EXTRACTING LABELS FOR OPEN-I DATASET","metadata":{}},{"cell_type":"code","source":"openI_labeled=pd.DataFrame({'Report Impression': comment_texts})\nopenI_labeled.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T21:14:20.398007Z","iopub.execute_input":"2023-11-15T21:14:20.398897Z","iopub.status.idle":"2023-11-15T21:14:20.408822Z","shell.execute_reply.started":"2023-11-15T21:14:20.398862Z","shell.execute_reply":"2023-11-15T21:14:20.407804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_pred_bools_int=[]\nfor arrays in best_pred_bools:\n    z=[int(pl) for pl in arrays]\n    best_pred_bools_int.append(z)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-15T21:20:18.911484Z","iopub.execute_input":"2023-11-15T21:20:18.912239Z","iopub.status.idle":"2023-11-15T21:20:18.939121Z","shell.execute_reply.started":"2023-11-15T21:20:18.912196Z","shell.execute_reply":"2023-11-15T21:20:18.938368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_pred_bools[:30]","metadata":{"execution":{"iopub.status.busy":"2023-11-15T21:26:39.948961Z","iopub.execute_input":"2023-11-15T21:26:39.949385Z","iopub.status.idle":"2023-11-15T21:26:39.958064Z","shell.execute_reply.started":"2023-11-15T21:26:39.949351Z","shell.execute_reply":"2023-11-15T21:26:39.957068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_pred_bools_int[:30]","metadata":{"execution":{"iopub.status.busy":"2023-11-15T21:21:20.856110Z","iopub.execute_input":"2023-11-15T21:21:20.856461Z","iopub.status.idle":"2023-11-15T21:21:20.871401Z","shell.execute_reply.started":"2023-11-15T21:21:20.856436Z","shell.execute_reply":"2023-11-15T21:21:20.870482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_df=pd.DataFrame( best_pred_bools_int)\ntemp_df.columns=test_label_cols\ntemp_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T21:24:05.216097Z","iopub.execute_input":"2023-11-15T21:24:05.216483Z","iopub.status.idle":"2023-11-15T21:24:05.245676Z","shell.execute_reply.started":"2023-11-15T21:24:05.216453Z","shell.execute_reply":"2023-11-15T21:24:05.244748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"openI_labeled=pd.concat([openI_labeled,temp_df],axis=1)\nopenI_labeled.head(11)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T21:28:29.832495Z","iopub.execute_input":"2023-11-15T21:28:29.833110Z","iopub.status.idle":"2023-11-15T21:28:29.851253Z","shell.execute_reply.started":"2023-11-15T21:28:29.833077Z","shell.execute_reply":"2023-11-15T21:28:29.850209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"openI_labeled.to_csv(\"openI_labeled.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-11-15T21:29:03.373276Z","iopub.execute_input":"2023-11-15T21:29:03.374328Z","iopub.status.idle":"2023-11-15T21:29:03.423458Z","shell.execute_reply.started":"2023-11-15T21:29:03.374283Z","shell.execute_reply":"2023-11-15T21:29:03.422470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Saving Models\n","metadata":{}},{"cell_type":"code","source":"# Print model's state_dict\nprint(\"Model's state_dict:\")\nfor param_tensor in model.state_dict():\n    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n\n# Print optimizer's state_dict\nprint(\"Optimizer's state_dict:\")\n#for var_name in optimizer.state_dict():\n#    print(var_name, \"\\t\", optimizer.state_dict()[var_name])","metadata":{"execution":{"iopub.status.busy":"2023-11-15T21:44:29.557242Z","iopub.execute_input":"2023-11-15T21:44:29.557630Z","iopub.status.idle":"2023-11-15T21:44:29.842816Z","shell.execute_reply.started":"2023-11-15T21:44:29.557590Z","shell.execute_reply":"2023-11-15T21:44:29.841909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/text_classifier_model.pt')","metadata":{"execution":{"iopub.status.busy":"2023-11-15T21:53:30.158469Z","iopub.execute_input":"2023-11-15T21:53:30.159693Z","iopub.status.idle":"2023-11-15T21:53:30.704570Z","shell.execute_reply.started":"2023-11-15T21:53:30.159651Z","shell.execute_reply":"2023-11-15T21:53:30.703566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Later to restore:\n#model.load_state_dict(torch.load(filepath))\n#model.eval()","metadata":{},"execution_count":null,"outputs":[]}]}